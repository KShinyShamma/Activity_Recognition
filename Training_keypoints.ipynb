{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMKQhFscvMLFXFaKRxlFZWX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KShinyShamma/Activity_Recognition/blob/main/Training_keypoints.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install ultralytics\n",
        "!pip install opencv-python\n",
        "import ultralytics\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJuASik2QT3c",
        "outputId": "749f2c24-ed90-4cef-d600-b888d82f9824"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.29-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.11-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Downloading ultralytics-8.3.29-py3-none-any.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.8/883.8 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.11-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.29 ultralytics-thop-2.0.11\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get Training Data"
      ],
      "metadata": {
        "id": "0Qh7TVYqr6aC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHmpmFARQNI-",
        "outputId": "909917d4-e1a3-44a6-9144-8815052dff3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-pose.pt to 'yolo11n-pose.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.97M/5.97M [00:00<00:00, 123MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Sitting_pose_estimation_output_1.mp4\n",
            "30.002752546105146\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Sitting_pose_estimation_output_2.mp4\n",
            "29.257854171532454\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Sitting_pose_estimation_output_3.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Sitting_pose_estimation_output_4.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Sitting_pose_estimation_output_5.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Sitting_pose_estimation_output_6.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Sitting_pose_estimation_output_7.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Sitting_pose_estimation_output_8.mp4\n",
            "30.109113368103213\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Sitting_pose_estimation_output_9.mp4\n",
            "29.97002997002997\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Sitting_pose_estimation_output_10.mp4\n",
            "24.135763670647393\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Sitting_pose_estimation_output_11.mp4\n",
            "24.135763670647393\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Sitting_pose_estimation_output_12.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Sitting_pose_estimation_output_13.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Sitting_pose_estimation_output_14.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Sitting_pose_estimation_output_15.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Laying_pose_estimation_output_1.mp4\n",
            "24.09689757756056\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Laying_pose_estimation_output_2.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Laying_pose_estimation_output_3.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Laying_pose_estimation_output_4.mp4\n",
            "29.97002997002997\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Laying_pose_estimation_output_5.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Laying_pose_estimation_output_6.mp4\n",
            "24.09689757756056\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Laying_pose_estimation_output_7.mp4\n",
            "28.752827107779996\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Laying_pose_estimation_output_8.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Laying_pose_estimation_output_9.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Laying_pose_estimation_output_10.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Laying_pose_estimation_output_11.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Laying_pose_estimation_output_12.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Laying_pose_estimation_output_13.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Laying_pose_estimation_output_14.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Laying_pose_estimation_output_15.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Jumping_pose_estimation_output_1.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Jumping_pose_estimation_output_2.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Jumping_pose_estimation_output_3.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Jumping_pose_estimation_output_4.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Jumping_pose_estimation_output_5.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Jumping_pose_estimation_output_6.mp4\n",
            "29.97002997002997\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Jumping_pose_estimation_output_7.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Jumping_pose_estimation_output_8.mp4\n",
            "24.12827691524561\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Jumping_pose_estimation_output_9.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Jumping_pose_estimation_output_10.mp4\n",
            "29.998089293675562\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Jumping_pose_estimation_output_11.mp4\n",
            "30.109397477501588\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Jumping_pose_estimation_output_12.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Jumping_pose_estimation_output_13.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Jumping_pose_estimation_output_14.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Jumping_pose_estimation_output_15.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Standing_pose_estimation_output_1.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Standing_pose_estimation_output_2.mp4\n",
            "30.10910825367172\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Standing_pose_estimation_output_3.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Standing_pose_estimation_output_4.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Standing_pose_estimation_output_5.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Standing_pose_estimation_output_6.mp4\n",
            "29.97002997002997\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Standing_pose_estimation_output_7.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Standing_pose_estimation_output_8.mp4\n",
            "24.12827691524561\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Standing_pose_estimation_output_9.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Standing_pose_estimation_output_10.mp4\n",
            "29.998089293675562\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Standing_pose_estimation_output_11.mp4\n",
            "30.109397477501588\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Standing_pose_estimation_output_12.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Standing_pose_estimation_output_13.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Standing_pose_estimation_output_14.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Train/Standing_pose_estimation_output_15.mp4\n",
            "Data successfully saved to /content/drive/MyDrive/P2/DATA/activity_Trainkeypoints_02.csv\n"
          ]
        }
      ],
      "source": [
        "model = YOLO(\"yolo11n-pose.pt\")\n",
        "\n",
        "# Activity\n",
        "activity_videos = {\n",
        "    'Sitting': ['/content/drive/MyDrive/P2/DATA/Sitting/001.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Sitting/002.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Sitting/003.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Sitting/004.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Sitting/005.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Sitting/006.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Sitting/007.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Sitting/008.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Sitting/009.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Sitting/010.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Sitting/011.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Sitting/012.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Sitting/013.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Sitting/014.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Sitting/015.mp4'\n",
        "                ],\n",
        "    'Laying': ['/content/drive/MyDrive/P2/DATA/Laying/001.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Laying/002.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Laying/003.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Laying/004.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Laying/005.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Laying/006.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Laying/007.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Laying/008.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Laying/009.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Laying/010.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Laying/011.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Laying/012.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Laying/013.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Laying/014.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Laying/015.mp4'\n",
        "                ],\n",
        "    'Jumping': ['/content/drive/MyDrive/P2/DATA/Jumping/001.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Jumping/002.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Jumping/003.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Jumping/004.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Jumping/005.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Jumping/006.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Jumping/007.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Jumping/008.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Jumping/009.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Jumping/010.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Jumping/011.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Jumping/012.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Jumping/013.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Jumping/014.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Jumping/015.mp4'\n",
        "                ],\n",
        "    'Standing': ['/content/drive/MyDrive/P2/DATA/Standing/001.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Standing/002.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Standing/003.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Standing/004.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Standing/005.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Standing/006.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Standing/007.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Standing/008.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Standing/009.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Standing/010.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Standing/011.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Standing/012.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Standing/013.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Standing/014.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Standing/015.mp4'\n",
        "                ],\n",
        "}\n",
        "\n",
        "# List to store keypoints data for all activities\n",
        "all_activity_points = []\n",
        "\n",
        "# LOop function for each activity\n",
        "for activity, video_paths in activity_videos.items():\n",
        "    for idx, video_path in enumerate(video_paths):\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "        # Get video properties\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        print(fps)\n",
        "        frames = 5\n",
        "\n",
        "        # Set up video writer to save output video\n",
        "        output_video_path = f'/content/drive/MyDrive/P2/YOLO/output01/Train/{activity}_pose_estimation_output_{idx + 1}.mp4'\n",
        "        #output_video_path = f'/content/drive/MyDrive/P2/YOLO/output01/{activity}_pose_estimation_output.mp4'\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mpv4')  # Codec\n",
        "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "        i = 0\n",
        "        a = 0\n",
        "\n",
        "        while cap.isOpened():\n",
        "            flag, frame = cap.read()\n",
        "\n",
        "            if not flag:\n",
        "                break\n",
        "\n",
        "            # Perform YOLO pose estimation on the frame\n",
        "            results = model(frame, verbose=False)\n",
        "\n",
        "            for r in results:\n",
        "                bound_box = r.boxes.xyxy\n",
        "                conf = r.boxes.conf.tolist()\n",
        "                keypoints = r.keypoints.xyn.tolist()\n",
        "\n",
        "                for index, box in enumerate(bound_box):\n",
        "                    if conf[index] > 0.75:\n",
        "                        # Draw bounding box around detected activity (the person)\n",
        "                        x1, y1, x2, y2 = box.tolist()\n",
        "                        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
        "\n",
        "                        # Optionally add a label for the activity\n",
        "                        label = f'{activity}'\n",
        "                        cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "                        # For skeleton??\n",
        "                        for kp_index, (x, y) in enumerate(keypoints[index]):\n",
        "                            cv2.circle(frame, (int(x * frame.shape[1]), int(y * frame.shape[0])), 5, (0, 255, 0), -1)\n",
        "                        skeleton_connections = [\n",
        "                            (0, 1), (1, 2), (2, 3), (3, 4),  # Left arm\n",
        "                            (0, 5), (5, 6), (6, 7), (7, 8),  # Right arm\n",
        "                            (9, 10), (10, 11), (11, 12),      # Left leg\n",
        "                            (9, 13), (13, 14), (14, 15),      # Right leg\n",
        "                            (0, 9)                            # Spine\n",
        "                        ]\n",
        "                        for p1, p2 in skeleton_connections:\n",
        "                            x1, y1 = keypoints[index][p1]\n",
        "                            x2, y2 = keypoints[index][p2]\n",
        "                            cv2.line(frame, (int(x1 * frame.shape[1]), int(y1 * frame.shape[0])),\n",
        "                                     (int(x2 * frame.shape[1]), int(y2 * frame.shape[0])), (0, 0, 255), 2)\n",
        "\n",
        "                        # Prepare keypoints data along with the activity label\n",
        "                        data = {'image_name': f'{activity}_person_{a}.jpg', 'activity': activity}\n",
        "                        for j in range(len(keypoints[index])):\n",
        "                            data[f'x{j}'] = keypoints[index][j][0]\n",
        "                            data[f'y{j}'] = keypoints[index][j][1]\n",
        "\n",
        "\n",
        "                        all_activity_points.append(data)\n",
        "                        a += 1\n",
        "\n",
        "            out.write(frame)\n",
        "\n",
        "            i += 1\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "        print(f'Video saved: {output_video_path}')\n",
        "\n",
        "# keypoints excel\n",
        "df = pd.DataFrame(all_activity_points)\n",
        "csv_file_path = '/content/drive/MyDrive/P2/DATA/activity_Trainkeypoints_02.csv'\n",
        "df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "print(f\"Data successfully saved to {csv_file_path}\")\n"
      ]
    }
  ]
}