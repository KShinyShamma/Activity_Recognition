{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPOWnVUfFDXxStiP0cFae1v"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwM9ZDM7I2NP",
        "outputId": "4d4f6fed-9940-4568-c4a7-8d5edb61c3c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.29-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.11-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.29-py3-none-any.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.8/883.8 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.11-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.29 ultralytics-thop-2.0.11\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install ultralytics\n",
        "!pip install opencv-python\n",
        "import ultralytics\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"yolo11n-pose.pt\")\n",
        "\n",
        "# Activity\n",
        "activity_videos = {\n",
        "   'Sitting': ['/content/drive/MyDrive/P2/DATA/Sitting/016.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Sitting/017.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Sitting/018.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Sitting/019.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Sitting/020.mp4'\n",
        "                ],\n",
        "    'Laying': ['/content/drive/MyDrive/P2/DATA/Laying/016.mp4',\n",
        "               '/content/drive/MyDrive/P2/DATA/Laying/017.mp4',\n",
        "               '/content/drive/MyDrive/P2/DATA/Laying/018.mp4',\n",
        "               '/content/drive/MyDrive/P2/DATA/Laying/019.mp4',\n",
        "               '/content/drive/MyDrive/P2/DATA/Laying/020.mp4'\n",
        "               ],\n",
        "    'Jumping': ['/content/drive/MyDrive/P2/DATA/Jumping/016.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Jumping/017.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Jumping/018.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Jumping/019.mp4',\n",
        "                '/content/drive/MyDrive/P2/DATA/Jumping/020.mp4'\n",
        "                ],\n",
        "    'Standing': ['/content/drive/MyDrive/P2/DATA/Standing/016.mp4',\n",
        "                 '/content/drive/MyDrive/P2/DATA/Standing/017.mp4',\n",
        "                 '/content/drive/MyDrive/P2/DATA/Standing/018.mp4',\n",
        "                 '/content/drive/MyDrive/P2/DATA/Standing/019.mp4',\n",
        "                 '/content/drive/MyDrive/P2/DATA/Standing/020.mp4'\n",
        "                ],\n",
        "}\n",
        "\n",
        "# List to store keypoints data for all activities\n",
        "all_activity_points = []\n",
        "\n",
        "# LOop function for each activity\n",
        "for activity, video_paths in activity_videos.items():\n",
        "    for idx, video_path in enumerate(video_paths):\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "        # Get video properties\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        print(fps)\n",
        "        frames = 5\n",
        "\n",
        "        # Set up video writer to save output video\n",
        "        output_video_path = f'/content/drive/MyDrive/P2/YOLO/output01/Test/{activity}_pose_estimation_output_{idx + 1}.mp4'\n",
        "        #output_video_path = f'/content/drive/MyDrive/P2/YOLO/output01/{activity}_pose_estimation_output.mp4'\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mpv4')  # Codec\n",
        "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "        i = 0\n",
        "        a = 0\n",
        "\n",
        "        while cap.isOpened():\n",
        "            flag, frame = cap.read()\n",
        "\n",
        "            if not flag:\n",
        "                break\n",
        "\n",
        "            # Perform YOLO pose estimation on the frame\n",
        "            results = model(frame, verbose=False)\n",
        "\n",
        "            for r in results:\n",
        "                bound_box = r.boxes.xyxy\n",
        "                conf = r.boxes.conf.tolist()\n",
        "                keypoints = r.keypoints.xyn.tolist()\n",
        "\n",
        "                for index, box in enumerate(bound_box):\n",
        "                    if conf[index] > 0.75:\n",
        "                        # Draw bounding box around detected activity (the person)\n",
        "                        x1, y1, x2, y2 = box.tolist()\n",
        "                        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
        "\n",
        "                        # Optionally add a label for the activity\n",
        "                        label = f'{activity}'\n",
        "                        cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "                        # For skeleton??\n",
        "                        for kp_index, (x, y) in enumerate(keypoints[index]):\n",
        "                            cv2.circle(frame, (int(x * frame.shape[1]), int(y * frame.shape[0])), 5, (0, 255, 0), -1)\n",
        "                        skeleton_connections = [\n",
        "                            (0, 1), (1, 2), (2, 3), (3, 4),  # Left arm\n",
        "                            (0, 5), (5, 6), (6, 7), (7, 8),  # Right arm\n",
        "                            (9, 10), (10, 11), (11, 12),      # Left leg\n",
        "                            (9, 13), (13, 14), (14, 15),      # Right leg\n",
        "                            (0, 9)                            # Spine\n",
        "                        ]\n",
        "                        for p1, p2 in skeleton_connections:\n",
        "                            x1, y1 = keypoints[index][p1]\n",
        "                            x2, y2 = keypoints[index][p2]\n",
        "                            cv2.line(frame, (int(x1 * frame.shape[1]), int(y1 * frame.shape[0])),\n",
        "                                     (int(x2 * frame.shape[1]), int(y2 * frame.shape[0])), (0, 0, 255), 2)\n",
        "\n",
        "                        # Prepare keypoints data along with the activity label\n",
        "                        data = {'image_name': f'{activity}_person_{a}.jpg', 'activity': activity}\n",
        "                        for j in range(len(keypoints[index])):\n",
        "                            data[f'x{j}'] = keypoints[index][j][0]\n",
        "                            data[f'y{j}'] = keypoints[index][j][1]\n",
        "\n",
        "\n",
        "                        all_activity_points.append(data)\n",
        "                        a += 1\n",
        "\n",
        "            out.write(frame)\n",
        "\n",
        "            i += 1\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "        print(f'Video saved: {output_video_path}')\n",
        "\n",
        "# keypoints excel\n",
        "df = pd.DataFrame(all_activity_points)\n",
        "csv_file_path = '/content/drive/MyDrive/P2/DATA/activity_Testkeypoints_02.csv'\n",
        "df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "print(f\"Data successfully saved to {csv_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1S1CryzI8mF",
        "outputId": "2f9fc6d2-f9da-402a-9425-62a386160978"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Test/Sitting_pose_estimation_output_1.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Test/Sitting_pose_estimation_output_2.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Test/Sitting_pose_estimation_output_3.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Test/Sitting_pose_estimation_output_4.mp4\n",
            "29.980781550288278\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Test/Sitting_pose_estimation_output_5.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Test/Laying_pose_estimation_output_1.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Test/Laying_pose_estimation_output_2.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Test/Laying_pose_estimation_output_3.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Test/Laying_pose_estimation_output_4.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Test/Laying_pose_estimation_output_5.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Test/Jumping_pose_estimation_output_1.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Test/Jumping_pose_estimation_output_2.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Test/Jumping_pose_estimation_output_3.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Test/Jumping_pose_estimation_output_4.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Test/Jumping_pose_estimation_output_5.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Test/Standing_pose_estimation_output_1.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Test/Standing_pose_estimation_output_2.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Test/Standing_pose_estimation_output_3.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Test/Standing_pose_estimation_output_4.mp4\n",
            "30.0\n",
            "Video saved: /content/drive/MyDrive/P2/YOLO/output01/Test/Standing_pose_estimation_output_5.mp4\n",
            "Data successfully saved to /content/drive/MyDrive/P2/DATA/activity_Testkeypoints_02.csv\n"
          ]
        }
      ]
    }
  ]
}